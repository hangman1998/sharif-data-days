{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.4 64-bit ('torch_env': conda)"
  },
  "interpreter": {
   "hash": "04546e26b63e01885cb4eec61ef38c0809d8f2802367581d36ec2bd0dbc452e8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from roboepics_client.roboepics_client import RoboEpicsClient\n",
    "\n",
    "# problem_id = 4\n",
    "# problem_enter_id = 185  \n",
    "\n",
    "# roboepics_client = RoboEpicsClient(problem_id, problem_enter_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals\n",
    "\n",
    "import collections\n",
    "from collections import Counter\n",
    "import gc\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import parsivar\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "source": [
    "stringy objects in are database are:\n",
    "query\n",
    "name1 & name2\n",
    "category\n",
    "test_queries\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "products = pd.read_csv('product_features.csv',chunksize=50000, index_col=0)\n",
    "p = next(products)\n",
    "# bow1 = set('بخار'.split(\" \"))\n",
    "# bow2 = set(ast.literal_eval(p.iloc[9,1]))\n",
    "p.head(10)\n",
    "# bow1.intersection(bow2)\n",
    "# len(bow1.intersection(bow2)) / len(bow1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# p = next(products)\n",
    "def score(bow1, bow2):\n",
    "    assert(len(bow1) > 0)\n",
    "    return len(bow1.intersection(bow2)) / len(bow1)\n",
    "\n",
    "def initial_filter(query, threshold):\n",
    "    products = pd.read_csv('product_features.csv',chunksize=100, index_col=0)\n",
    "    candid = pd.DataFrame()\n",
    "    i=0\n",
    "    for p in products:\n",
    "        # p['score'] = p.apply(lambda row: score(set(query.split(\" \")), set(ast.literal_eval(row.bow))), axis=1)\n",
    "        # candid.append(p[p['score'] >= threshold])\n",
    "        candid.append(p)\n",
    "        i += 1\n",
    "        if i == 3:\n",
    "            break\n",
    "        # break\n",
    "    # print(candid.head(5))\n",
    "    # candid = candid.sort_values(by='score')\n",
    "    # if len(candid) > 10:\n",
    "    #     return candid.iloc[:10,:]\n",
    "    # else:\n",
    "    return candid\n",
    "    \n",
    "initial_filter(\"STEAM\", 0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(row):\n",
    "    bow = set()\n",
    "    sellers = row['sellers']\n",
    "    cat = row['category_name']\n",
    "    bow = bow.union( set(cat.split(\" \")))\n",
    "    num_avail_sellers = 0\n",
    "    min_price = 1e30\n",
    "    for seller in sellers:\n",
    "        bow = bow.union(set(seller['name1'].split(\" \")))\n",
    "        bow = bow.union(set(seller['name2'].split(\" \")))\n",
    "        if seller['availability']:\n",
    "            num_avail_sellers += 1\n",
    "        if min_price > seller['price']:\n",
    "            min_price = seller['price']\n",
    "\n",
    "    return pd.Series({'id': row._id, 'bow':bow, 'min_price':min_price, 'num_of_sellers': num_avail_sellers})\n",
    "\n",
    "products = pd.read_json(\"base_products.json\", lines=True, chunksize=10000)\n",
    "product_features = pd.DataFrame()\n",
    "for p in products:\n",
    "    product_features = product_features.append(p.apply(process, axis=1))\n",
    "product_features.to_csv('product_features')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# test_queries = test_queries.astype({0: 'str'})\n",
    "# test_queries = pd.read_json(\"queries_test_offline.json\", lines=True, chunksize=10000)\n",
    "# queries = pd.read_json(\"search_log_train.json\", lines=True, chunksize=10000)\n",
    "# for q in test_queries:\n",
    "# q['bow'] = q.apply(lambda row: set(row[0].split(\" \")), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = pd.read_json(\"queries_test_offline.json\", lines=True, chunksize=1)\n",
    "q = next(test_queries)\n",
    "initial_filter(q, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# hist = Counter()\n",
    "\n",
    "\n",
    "# for q in tqdm(test_queries):\n",
    "#    hist = hist + Counter(' '.join(q[0].values))\n",
    "# for q in tqdm(queries):   h# t = hist + Counter(' '.join(q[0].raw_querylues))plen()hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candids = [1,2]\n",
    "candids += [1,2,3]\n",
    "candids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.most_common(332)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}